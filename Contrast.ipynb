{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29128,"status":"ok","timestamp":1654675947067,"user":{"displayName":"TIL22 010","userId":"10692269585455366539"},"user_tz":-540},"id":"GWBdbDFw8pBI","outputId":"44c9f4c8-0bee-4960-9a33-b28a1e13a275"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#microservice for improving training data\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58jQrQcF9C4T"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","#use this to increase contrast in photos for ease of feature extraction\n","def contrast_up(filename):\n","  img = cv2.imread('/content/drive/My Drive/CVFinal/Images/'+filename, 1)\n","  # converting to LAB color space\n","  lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","  l_channel, a, b = cv2.split(lab)\n","\n","  # Applying CLAHE to L-channel\n","  # feel free to try different values for the limit and grid size:\n","  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","  cl = clahe.apply(l_channel)\n","\n","  ##we can also try the below for an affine transform, but no need\n","  ##new_image = cv.convertScaleAbs(image, alpha=alpha, beta=beta)\n","\n","  # merge the CLAHE enhanced L-channel with the a and b channel\n","  limg = cv2.merge((cl,a,b))\n","\n","  # Converting image from LAB Color model to BGR color spcae\n","  enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n","\n","  #then write into a new file, with same name\n","  cv2.imwrite('/content/drive/My Drive/CVContrast/'+filename, enhanced_img)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpypBGwz9kzI"},"outputs":[],"source":["import json\n","jsonfile = open('/content/drive/MyDrive/CVFinal/qualifiers_finals_no_annotations.json')\n","data = json.load(jsonfile)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Fbya-6Jh_Mtg"},"outputs":[],"source":["#for each image in the json file, find the namesake, then increase contrast\n","for image in data[\"images\"]:\n","  try:\n","    contrast_up(image[\"file_name\"])\n","\n","  except:\n","    print(\"file missing\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMkVk0Vs_sZp"},"outputs":[],"source":[""]}],"metadata":{"colab":{"machine_shape":"hm","name":"Contrast.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPYa1BUJ6dzBMPKkNMkI/Pg"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}